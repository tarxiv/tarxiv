services:
  # Setup elasticsearch database with defined user roles and passwords
  setup_elasticsearch:
    profiles:
      - setup_elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:9.0.2
    init: true
    entrypoint: /entrypoint.sh
    volumes:
      - ./entrypoint.sh:/entrypoint.sh:ro,Z
      - ./lib.sh:/lib.sh:ro,Z
      - ./roles:/roles:ro,Z
    environment:
      ELASTIC_PASSWORD: ${TARXIV_ELASTIC_PASSWORD:-}
      LOGSTASH_INTERNAL_PASSWORD: ${TARXIV_LOGSTASH_INTERNAL_PASSWORD:-}
      KIBANA_SYSTEM_PASSWORD: ${TARXIV_KIBANA_SYSTEM_PASSWORD:-}
      BEATS_SYSTEM_PASSWORD: ${TARXIV_BEATS_SYSTEM_PASSWORD:-}

    networks:
      - tarxiv_net
    depends_on:
      - elasticsearch

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.0.2
    volumes:
      - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z
      - ${TARXIV_ELASTIC_DATA_DIR}:/usr/share/elasticsearch/data:Z
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      node.name: elasticsearch
      discovery.type: single-node
      ELASTIC_PASSWORD: ${TARXIV_ELASTIC_PASSWORD}
      ES_JAVA_OPTS: -Xms2048m -Xmx2048m
    networks:
      - tarxiv_net
    restart: unless-stopped

  logstash:
    image: docker.elastic.co/logstash/logstash:9.0.2
    volumes:
      - ./logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./tarxiv_logstash.conf:/usr/share/logstash/pipeline/tarxiv_logstash.conf:ro,Z
    ports:
      - 5044:5044
      - 5045:5045
      - 5046:5046
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LS_JAVA_OPTS: -Xms512m -Xmx512m
      LOGSTASH_INTERNAL_PASSWORD: ${TARXIV_LOGSTASH_INTERNAL_PASSWORD}
      ELASTIC_PASSWORD: ${TARXIV_ELASTIC_PASSWORD}
    networks:
      - tarxiv_net
    depends_on:
      - elasticsearch
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:9.0.2
    volumes:
      - ./kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - 5601:5601
    environment:
        KIBANA_SYSTEM_PASSWORD: ${TARXIV_KIBANA_SYSTEM_PASSWORD}
    networks:
      - tarxiv_net
    depends_on:
      - elasticsearch
    restart: unless-stopped

  couchbase:
    image: couchbase:latest
    volumes:
      - ${TARXIV_COUCHBASE_DATA_DIR}:/opt/couchbase/var/lib/couchbase/data:Z
      - ./init_server.sh:/init_server.sh:ro,Z
    ports:
      - 8091-8096:8091-8096
      - 11210-11211:11210-11211
    networks:
      - tarxiv_net
    entrypoint: /init_server.sh
    environment:
      TARXIV_COUCHBASE_HOST: ${TARXIV_COUCHBASE_HOST}
      TARXIV_COUCHBASE_ADMIN_USERNAME: ${TARXIV_COUCHBASE_ADMIN_USERNAME:-}
      TARXIV_COUCHBASE_ADMIN_PASSWORD: ${TARXIV_COUCHBASE_ADMIN_PASSWORD:-}
      TARXIV_COUCHBASE_API_USERNAME: ${TARXIV_COUCHBASE_API_USERNAME:-}
      TARXIV_COUCHBASE_API_PASSWORD: ${TARXIV_COUCHBASE_API_PASSWORD:-}
      TARXIV_COUCHBASE_PIPELINE_USERNAME: ${TARXIV_COUCHBASE_PIPELINE_USERNAME:-}
      TARXIV_COUCHBASE_PIPELINE_PASSWORD: ${TARXIV_COUCHBASE_PIPELINE_PASSWORD:-}
    restart: unless-stopped

  redis:
    image: redis:latest
    volumes:
      - ${TARXIV_REDIS_DATA_DIR}:/data
    ports:
      - 6379:6379
    environment:
      - REDIS_PASSWORD:${TARXIV_REDIS_PASSWORD}
    networks:
      - tarxiv_net

  kafka-broker:
    image: confluentinc/cp-kafka:8.0.0
    hostname: broker
    container_name: broker
    ports:
      - "9092:9092"
      - "9101:9101"
    networks:
      - tarxiv_net
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka-broker:29092,PLAINTEXT_HOST://${TARXIV_KAFKA_HOST}:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: kafka-broker
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka-broker:29092,CONTROLLER://kafka-broker:29093,PLAINTEXT_HOST://${TARXIV_KAFKA_HOST}:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      # Randomly generated UUID4
      CLUSTER_ID: '8d885d52-1c7f-4f4d-8ae3-59df3e3c46cb'

  kafka-schema-registry:
    image: confluentinc/cp-schema-registry:8.0.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - kafka-broker
    ports:
      - "8081:8081"
    networks:
      - tarxiv_net
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
      SCHEMA_REGISTRY_LISTENERS: 'http://${TARXIV_KAFKA_HOST}:8081'

  kafka-connect:
    image: cnfldemos/kafka-connect-datagen:0.6.4-7.6.0
    hostname: connect
    container_name: connect
    depends_on:
      - kafka-broker
      - kafka-schema-registry
    ports:
      - "8083:8083"
    networks:
      - tarxiv_net
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'kafka-broker:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"

  kafka-rest-proxy:
    image: confluentinc/cp-kafka-rest:8.0.0
    depends_on:
      - kafka-broker
      - kafka-schema-registry
    ports:
      - 8082:8082
    networks:
      - tarxiv_net
    hostname: rest-proxy
    container_name: rest-proxy
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'kafka-broker:29092'
      KAFKA_REST_LISTENERS: "http://${TARXIV_KAFKA_HOST}:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'


  kafbat-ui:
    container_name: kafbat-ui
    image: ghcr.io/kafbat/kafka-ui:latest
    ports:
      - 8080:8080
    networks:
      - tarxiv_net
    depends_on:
      - kafka-broker
      - kafka-schema-registry
      - kafka-connect
    environment:
      KAFKA_CLUSTERS_0_NAME: tarxiv_cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-broker:29092
      KAFKA_CLUSTERS_0_METRICS_PORT: 9101
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: connect
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
      KAFKA_CLUSTERS_0_METRICS_STORE_PROMETHEUS_URL: "http://prometheus:9090"
      KAFKA_CLUSTERS_0_METRICS_STORE_PROMETHEUS_REMOTEWRITE: 'true'
      KAFKA_CLUSTERS_0_METRICS_STORE_KAFKA_TOPIC: "kafka_metrics"
      DYNAMIC_CONFIG_ENABLED: 'true'

  prometheus:
    image: prom/prometheus:latest
    hostname: prometheus
    container_name: prometheus
    ports:
      - 9090:9090
    networks:
      - tarxiv_net
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command: --web.enable-remote-write-receiver  --config.file=/etc/prometheus/prometheus.yml

  kafka-init:
    image: confluentinc/cp-kafka:8.0.0
    networks:
      - tarxiv_net
    depends_on:
      - kafka-broker
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka-broker:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka-broker:29092 --create --if-not-exists --topic spark-detections --replication-factor 1 --partitions 16
      kafka-topics --bootstrap-server kafka-broker:29092 --create --if-not-exists --topic spark-sink --replication-factor 1 --partitions 4

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka-broker:29092 --list
      "

networks:
  tarxiv_net:
    driver: bridge

volumes:
  elasticsearch: